# 09 - Demo Dry Run

**Time:** 25 minutes
**Priority:** P0 - Demo rehearsal
**Updated:** January 9, 2026 (Milestone 6 - Current Demo Script)

---

## Overview

This is the full demo script. Run through it 3x before the actual demo to ensure consistency.

---

## Pre-Demo Setup (Night Before)

```
‚ñ° Run seed_demo_data.py to populate database
‚ñ° Verify .env has TAVILY_API_KEY
‚ñ° Test all demo commands 3x
‚ñ° Prepare backup plan (screenshots, video)
‚ñ° Charge laptop, test WiFi
```

## Day-Of Setup (15 min before)

```
‚ñ° App running on localhost:8501
‚ñ° All toggles ON: Context Engineering + Memory
‚ñ° MCP Mode: OFF (will toggle during demo)
‚ñ° Memory cleared (üóëÔ∏è Clear Session Memory)
‚ñ° Browser in presentation mode (hide bookmarks, dev tools)
‚ñ° Debug panel visible at bottom
‚ñ° Slides ready, synced with demo flow
```

---

## Demo Script (20 minutes)

### Intro (0-2 min)

```
‚ñ° Slides ready
‚ñ° App open and loaded
‚ñ° All toggles visible in sidebar
‚ñ° Memory Stats showing 0/0/0
```

**Talking Points:**
- Flow Companion: AI-powered task management
- Built on MongoDB Atlas + Claude
- Demonstrates Context Engineering + Memory Engineering

---

### Raw Speed - Slash Commands (2-4 min)

Show that slash commands bypass LLM and hit MongoDB directly.

| Command | Expected | Latency | Pass |
|---------|----------|---------|------|
| `/tasks` | All tasks | <200ms | ‚ñ° |
| `/tasks status:in_progress` | Filtered | <150ms | ‚ñ° |
| `/search debugging` | Search results | <500ms | ‚ñ° |
| `/projects AgentOps` | Project details | <200ms | ‚ñ° |

**Talking Points:**
- Direct to MongoDB - no LLM overhead
- Sub-second response times
- Good for power users

---

### LLM Queries (4-7 min)

Show natural language understanding with tool calling.

| Query | Expected | Pass |
|-------|----------|------|
| "What are my tasks?" | Tool called, formatted response | ‚ñ° |
| "Show me the AgentOps project" | Tool called, filtered response | ‚ñ° |
| "I finished the debugging doc" | Search ‚Üí Confirm ‚Üí Complete | ‚ñ° |

**Talking Points:**
- Natural language interface
- LLM interprets intent, calls tools
- Same MongoDB data, different interface

---

### Voice (7-9 min)

Show voice input produces same results.

| Speak | Expected | Pass |
|-------|----------|------|
| üé§ "What's in progress?" | Same as text | ‚ñ° |
| üé§ "Add a note to voice agent: WebSocket working" | Note added | ‚ñ° |

**Talking Points:**
- Speech-to-text with Whisper/Deepgram
- Same LLM processing as text
- Hands-free operation

---

### Memory Engineering Demo (9-17 min) ‚≠ê CORE SECTION

**This is the main demo - show 5-tier memory architecture value.**

#### Step 1: Baseline Query (Slash Command)

| Action | Expected | Latency | Pass |
|--------|----------|---------|------|
| `/tasks` | Shows all tasks (15 from seed data) | <200ms | ‚ñ° |

**Talking Point:** Direct MongoDB query - our baseline.

#### Step 2: Episodic Memory (Action History)

| Action | Expected | Pass |
|--------|----------|------|
| "What was completed on Project Alpha?" | Shows completed tasks from history | ‚ñ° |
| Check debug panel | `get_action_history` tool called | ‚ñ° |

**Talking Point:** Episodic Memory tracks what happened - persistent action history.

#### Step 3: Semantic Memory (Preferences)

| Action | Expected | Pass |
|--------|----------|------|
| "I'm focusing on Project Alpha" | Stores preference | ‚ñ° |
| Check Memory Stats | Semantic Memory: 1 entry | ‚ñ° |

**Talking Point:** Semantic Memory learns user preferences - stored permanently.

#### Step 4: Working Memory (Session Context)

| Action | Expected | Pass |
|--------|----------|------|
| "What should I work on next?" | Suggests Project Alpha tasks (uses preference) | ‚ñ° |
| Check Memory Stats | Working Memory: 1 entry (current focus) | ‚ñ° |

**Talking Point:** Working Memory maintains conversation context - knows "next" refers to Project Alpha.

#### Step 5: Memory Contrast (Toggle OFF)

| Action | Expected | Pass |
|--------|----------|------|
| [Toggle Working Memory OFF in sidebar] | Toggle shows unchecked | ‚ñ° |
| "What should I work on next?" | Shows ALL tasks OR asks "which project?" | ‚ñ° |

**Talking Point:** Without Working Memory, context is lost - system doesn't remember our focus.

**[Toggle Working Memory back ON]**

#### Step 6: MCP Agent (Web Search) - NEW in Milestone 6

| Action | Expected | Pass |
|--------|----------|------|
| [Toggle MCP Mode ON in Experimental section] | Shows "MCP Servers: 1 connected (Tavily)" | ‚ñ° |
| "Research gaming market and create GTM project with tasks" | Multi-step workflow executes | ‚ñ° |

**Expected Execution Flow:**
```
Step 1/3: Research gaming market trends
  ‚Üí Routing to MCP Agent (Tavily)...
  ‚Üí ‚úì Research completed via tavily-search

Step 2/3: Create GTM project for gaming
  ‚Üí Detected GTM project
  ‚Üí Loading template from procedural memory...
  ‚Üí ‚úì Found template: GTM Roadmap Template
  ‚Üí ‚úì Project created: Gaming Market

Step 3/3: Generate tasks from template
  ‚Üí Phase: Research (4 tasks)
  ‚Üí Phase: Strategy (4 tasks)
  ‚Üí Phase: Execution (4 tasks)
  ‚Üí ‚úì Generated 12 tasks across 3 phases

Multi-step execution complete: 3/3 steps successful
```

**Talking Points:**
- Procedural Memory: GTM template loaded automatically
- MCP Agent: Dynamic tool discovery (Tavily web search)
- Knowledge Cache: Research results cached for 7 days
- Multi-step workflows: Automatic orchestration

#### Step 7: Knowledge Cache (Memory Reuse)

| Action | Expected | Pass |
|--------|----------|------|
| "What do you know about gaming?" | Uses cached research (~0.5s, no new API call) | ‚ñ° |
| Check response | Shows "üìö Source: Knowledge Cache" | ‚ñ° |

**Talking Point:** Knowledge Cache (Semantic Memory) - avoids redundant API calls, 7-day TTL.

---

### Evals Dashboard (15-17 min) - Optional

Show metrics if time permits.

| Check | Expected | Pass |
|-------|----------|------|
| Dashboard loads | Shows 24 tests, 10 competencies | ‚ñ° |
| Run eval | Tests execute | ‚ñ° |
| Show metrics | Pass rates visible | ‚ñ° |

**Talking Points:**
- Systematic evaluation framework
- 4 capabilities: AR, TTL, LRU, CR
- Quantified memory impact

---

### Wrap-up (17-25 min)

```
‚ñ° Debug panel shows clear breakdown
‚ñ° Latency numbers support narrative
‚ñ° All 5 memory types demonstrated
‚ñ° MCP Agent and multi-step workflows shown
‚ñ° Q&A ready
```

**Key Takeaways:**
1. **5-Tier Memory Architecture**: Working, Episodic, Semantic, Procedural, Shared
2. **Context Engineering**: 40-60% latency reduction through optimization
3. **MCP Agent (Milestone 6)**: Dynamic tool discovery with Tavily integration
4. **Multi-Step Workflows**: Automatic orchestration (Research ‚Üí Create ‚Üí Generate)
5. **Knowledge Cache**: 7-day TTL, 90% faster on repeated queries
6. **MongoDB Atlas**: Unified memory layer with vector search
7. **Production-Ready**: 47 tests, 90% coverage

---

## Final Verification

```
‚ñ° No console errors
‚ñ° No UI glitches
‚ñ° All queries work consistently
‚ñ° Demo runs 3x without issues
‚ñ° Backup plan ready (pre-recorded video)
‚ñ° Slides sync with demo flow
```

---

## Quick Reference Card

Print this for demo day:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FLOW COMPANION - DEMO QUICK REFERENCE (Jan 15, 2026)    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ EXACT DEMO SEQUENCE (8 Commands):                       ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 1. /tasks                                                ‚îÇ
‚îÇ    ‚Üí Shows all 15 tasks (<200ms)                        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 2. "What was completed on Project Alpha?"               ‚îÇ
‚îÇ    ‚Üí Episodic Memory (action history)                   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 3. "I'm focusing on Project Alpha"                      ‚îÇ
‚îÇ    ‚Üí Semantic Memory (stores preference)                ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 4. "What should I work on next?"                        ‚îÇ
‚îÇ    ‚Üí Working Memory (uses Project Alpha context)        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 5. [Toggle Working Memory OFF]                          ‚îÇ
‚îÇ    ‚Üí "What should I work on next?"                      ‚îÇ
‚îÇ    ‚Üí Shows context is lost                              ‚îÇ
‚îÇ    [Toggle Working Memory back ON]                      ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 6. [Toggle MCP Mode ON]                                 ‚îÇ
‚îÇ    ‚Üí "Research gaming market and create GTM project     ‚îÇ
‚îÇ        with tasks"                                       ‚îÇ
‚îÇ    ‚Üí Multi-step workflow (3 steps, ~10s)                ‚îÇ
‚îÇ    ‚Üí Procedural Memory (GTM template)                   ‚îÇ
‚îÇ    ‚Üí MCP Agent (Tavily research)                        ‚îÇ
‚îÇ    ‚Üí 12 tasks created automatically                      ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ 7. "What do you know about gaming?"                     ‚îÇ
‚îÇ    ‚Üí Knowledge Cache hit (~0.5s, no API call)           ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ EXPECTED LATENCIES:                                      ‚îÇ
‚îÇ   /tasks:            <200ms                              ‚îÇ
‚îÇ   Text queries:      6-12s (optimized)                  ‚îÇ
‚îÇ   MCP + multi-step:  ~10s (3 steps)                     ‚îÇ
‚îÇ   Knowledge cache:   <1s (90% faster)                   ‚îÇ
‚îÇ   Memory ops:        <50ms                               ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ STATS TO MENTION:                                        ‚îÇ
‚îÇ   ‚Ä¢ 5-tier memory architecture                          ‚îÇ
‚îÇ   ‚Ä¢ 47 tests, 90% coverage                              ‚îÇ
‚îÇ   ‚Ä¢ 40-60% latency reduction (context engineering)      ‚îÇ
‚îÇ   ‚Ä¢ 7-day knowledge cache TTL                           ‚îÇ
‚îÇ   ‚Ä¢ Vector search: 1024-dim Voyage AI embeddings        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Troubleshooting During Demo

| Issue | Quick Fix |
|-------|-----------|
| Query stuck | Refresh page, retry |
| Memory not updating | Check toggle is ON |
| Slow response | Mention "first query warming up" |
| Voice not working | Switch to text, "voice works similarly" |
| Tool error | "Let me try that differently" |

---

## Verification After Each Dry Run

```
‚ñ° All 7 demo commands executed successfully
‚ñ° Multi-step workflow created 12 tasks with correct phases
‚ñ° Knowledge cache showed "üìö Source: Knowledge Cache"
‚ñ° Memory toggles demonstrated clear before/after
‚ñ° Debug panel showed tool calls and timing
‚ñ° No errors in console
‚ñ° Backup plan ready if any step fails
```

---

*Demo Dry Run Guide v3.0*
*Updated for Milestone 6: MCP Agent & Multi-Step Workflows*
*MongoDB Developer Day - January 15, 2026*